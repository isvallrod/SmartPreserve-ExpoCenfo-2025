import { type NextRequest, NextResponse } from "next/server"
import { generateText } from "ai"
import { openai } from "@ai-sdk/openai"

export async function POST(request: NextRequest) {
  try {
    const { message, sensorData } = await request.json()

    if (!message || !sensorData) {
      return NextResponse.json({ error: "Mensaje y datos requeridos" }, { status: 400 })
    }

    // Determinar tipo de an√°lisis basado en el mensaje
    const analysisType = determineAnalysisType(message)

    let response = ""
    let chartData = null

    switch (analysisType) {
      case "statistical":
        response = await generateStatisticalAnalysis(sensorData, message)
        break
      case "chart":
        const chartResult = await generateChartAnalysis(sensorData, message)
        response = chartResult.response
        chartData = chartResult.chartData
        break
      case "ai":
        response = await generateAIAnalysis(sensorData, message)
        break
      default:
        response = await generateGeneralResponse(sensorData, message)
    }

    return NextResponse.json({
      response,
      analysisType,
      chartData,
    })
  } catch (error) {
    console.error("Error en chat-analyze:", error)
    return NextResponse.json(
      {
        response: "Lo siento, hubo un error procesando tu solicitud. Por favor intenta nuevamente.",
        analysisType: "error",
      },
      { status: 500 },
    )
  }
}

function determineAnalysisType(message: string): string {
  const lowerMessage = message.toLowerCase()

  if (
    lowerMessage.includes("estad√≠stic") ||
    lowerMessage.includes("media") ||
    lowerMessage.includes("promedio") ||
    lowerMessage.includes("desviaci√≥n") ||
    lowerMessage.includes("m√≠nimo") ||
    lowerMessage.includes("m√°ximo")
  ) {
    return "statistical"
  }

  if (
    lowerMessage.includes("gr√°fico") ||
    lowerMessage.includes("grafica") ||
    lowerMessage.includes("chart") ||
    lowerMessage.includes("visualiz") ||
    lowerMessage.includes("hora") ||
    lowerMessage.includes("per√≠odo") ||
    lowerMessage.includes("tiempo")
  ) {
    return "chart"
  }

  if (
    lowerMessage.includes("ia") ||
    lowerMessage.includes("inteligencia") ||
    lowerMessage.includes("recomend") ||
    lowerMessage.includes("analiz") ||
    lowerMessage.includes("patr√≥n") ||
    lowerMessage.includes("tendencia")
  ) {
    return "ai"
  }

  return "general"
}

async function generateStatisticalAnalysis(sensorData: any[], message: string): Promise<string> {
  const lightValues = sensorData.map((d) => d.lightLevel || 0).filter((v) => v > 0)

  if (lightValues.length === 0) {
    return "No hay datos suficientes para realizar un an√°lisis estad√≠stico."
  }

  const mean = lightValues.reduce((sum, val) => sum + val, 0) / lightValues.length
  const min = Math.min(...lightValues)
  const max = Math.max(...lightValues)
  const median = lightValues.sort((a, b) => a - b)[Math.floor(lightValues.length / 2)]

  // Desviaci√≥n est√°ndar
  const variance = lightValues.reduce((sum, val) => sum + Math.pow(val - mean, 2), 0) / lightValues.length
  const stdDev = Math.sqrt(variance)

  return `üìä **AN√ÅLISIS ESTAD√çSTICO COMPLETO**

**Datos analizados:** ${lightValues.length} registros

**Medidas de tendencia central:**
‚Ä¢ Media: ${mean.toFixed(2)}
‚Ä¢ Mediana: ${median}
‚Ä¢ Moda: ${findMode(lightValues)}

**Medidas de dispersi√≥n:**
‚Ä¢ M√≠nimo: ${min}
‚Ä¢ M√°ximo: ${max}
‚Ä¢ Rango: ${max - min}
‚Ä¢ Desviaci√≥n est√°ndar: ${stdDev.toFixed(2)}
‚Ä¢ Varianza: ${variance.toFixed(2)}

**Interpretaci√≥n:**
${interpretStatistics(mean, stdDev, min, max)}

**Distribuci√≥n por rangos:**
${generateDistribution(lightValues)}`
}

async function generateChartAnalysis(
  sensorData: any[],
  message: string,
): Promise<{ response: string; chartData: any }> {
  // Determinar per√≠odo solicitado
  const period = extractTimePeriod(message)
  const filteredData = filterDataByPeriod(sensorData, period)

  const chartData = {
    labels: filteredData.map((d) => new Date(d.timestamp).toLocaleTimeString("es-ES")),
    values: filteredData.map((d) => d.lightLevel || 0),
    period: period,
    dataPoints: filteredData.length,
  }

  const response = `üìà **GR√ÅFICO GENERADO - ${period.toUpperCase()}**

**Per√≠odo:** ${period}
**Puntos de datos:** ${filteredData.length}
**Rango temporal:** ${
    filteredData.length > 0
      ? `${new Date(filteredData[filteredData.length - 1].timestamp).toLocaleString("es-ES")} - ${new Date(filteredData[0].timestamp).toLocaleString("es-ES")}`
      : "Sin datos"
  }

**Resumen del gr√°fico:**
‚Ä¢ Valor m√≠nimo: ${Math.min(...chartData.values)}
‚Ä¢ Valor m√°ximo: ${Math.max(...chartData.values)}
‚Ä¢ Promedio: ${(chartData.values.reduce((a, b) => a + b, 0) / chartData.values.length).toFixed(2)}

**Tendencia observada:**
${analyzeTrend(chartData.values)}

*Los datos del gr√°fico est√°n disponibles en el panel lateral para visualizaci√≥n.*`

  return { response, chartData }
}

async function generateAIAnalysis(sensorData: any[], message: string): Promise<string> {
  const prompt = `
Eres un experto en an√°lisis de datos IoT. Analiza estos datos del sensor de luz ESP32:

Datos: ${JSON.stringify(sensorData.slice(0, 20), null, 2)}

Pregunta del usuario: "${message}"

Proporciona un an√°lisis inteligente que incluya:
1. Interpretaci√≥n de los patrones de luz
2. Posibles causas de las variaciones
3. Recomendaciones espec√≠ficas
4. Predicciones o insights

Responde de forma conversacional y √∫til.
`

  const { text } = await generateText({
    model: openai("gpt-4o-mini"),
    prompt: prompt,
    temperature: 0.7,
    maxTokens: 800,
  })

  return `üß† **AN√ÅLISIS CON INTELIGENCIA ARTIFICIAL**

${text}

---
*An√°lisis generado por IA basado en ${sensorData.length} puntos de datos*`
}

async function generateGeneralResponse(sensorData: any[], message: string): Promise<string> {
  const prompt = `
El usuario pregunta: "${message}"

Datos disponibles del sensor ESP32: ${sensorData.length} registros de luz (0-4095)
√öltimo valor: ${sensorData[0]?.lightLevel || "N/A"}

Responde de forma √∫til y sugiere qu√© tipo de an√°lisis podr√≠a ser m√°s apropiado.
`

  const { text } = await generateText({
    model: openai("gpt-4o-mini"),
    prompt: prompt,
    temperature: 0.5,
    maxTokens: 400,
  })

  return text
}

// Funciones auxiliares
function findMode(values: number[]): number {
  const frequency: { [key: number]: number } = {}
  values.forEach((val) => (frequency[val] = (frequency[val] || 0) + 1))
  return Number.parseInt(
    Object.keys(frequency).reduce((a, b) => (frequency[Number.parseInt(a)] > frequency[Number.parseInt(b)] ? a : b)),
  )
}

function interpretStatistics(mean: number, stdDev: number, min: number, max: number): string {
  let interpretation = ""

  if (mean < 1000) {
    interpretation += "‚Ä¢ Ambiente predominantemente oscuro\n"
  } else if (mean < 2500) {
    interpretation += "‚Ä¢ Condiciones de luz moderadas\n"
  } else {
    interpretation += "‚Ä¢ Ambiente bien iluminado\n"
  }

  if (stdDev > 1000) {
    interpretation += "‚Ä¢ Alta variabilidad en los datos (cambios significativos)\n"
  } else {
    interpretation += "‚Ä¢ Baja variabilidad (condiciones estables)\n"
  }

  return interpretation
}

function generateDistribution(values: number[]): string {
  const ranges = [
    { min: 0, max: 500, label: "Muy oscuro" },
    { min: 501, max: 1500, label: "Oscuro" },
    { min: 1501, max: 3000, label: "Medio" },
    { min: 3001, max: 4095, label: "Brillante" },
  ]

  return ranges
    .map((range) => {
      const count = values.filter((v) => v >= range.min && v <= range.max).length
      const percentage = ((count / values.length) * 100).toFixed(1)
      return `‚Ä¢ ${range.label}: ${count} registros (${percentage}%)`
    })
    .join("\n")
}

function extractTimePeriod(message: string): string {
  const lowerMessage = message.toLowerCase()

  if (lowerMessage.includes("hora") || lowerMessage.includes("1h")) return "√∫ltima hora"
  if (lowerMessage.includes("2 hora") || lowerMessage.includes("2h")) return "√∫ltimas 2 horas"
  if (lowerMessage.includes("24") || lowerMessage.includes("d√≠a")) return "√∫ltimas 24 horas"
  if (lowerMessage.includes("semana")) return "√∫ltima semana"

  return "√∫ltimos datos disponibles"
}

function filterDataByPeriod(data: any[], period: string): any[] {
  const now = new Date()
  const cutoffTime = new Date()

  switch (period) {
    case "√∫ltima hora":
      cutoffTime.setHours(now.getHours() - 1)
      break
    case "√∫ltimas 2 horas":
      cutoffTime.setHours(now.getHours() - 2)
      break
    case "√∫ltimas 24 horas":
      cutoffTime.setDate(now.getDate() - 1)
      break
    case "√∫ltima semana":
      cutoffTime.setDate(now.getDate() - 7)
      break
    default:
      return data.slice(0, 20) // √öltimos 20 registros
  }

  return data.filter((d) => new Date(d.timestamp) >= cutoffTime)
}

function analyzeTrend(values: number[]): string {
  if (values.length < 3) return "Datos insuficientes para determinar tendencia"

  const firstThird = values.slice(0, Math.floor(values.length / 3))
  const lastThird = values.slice(-Math.floor(values.length / 3))

  const firstAvg = firstThird.reduce((a, b) => a + b, 0) / firstThird.length
  const lastAvg = lastThird.reduce((a, b) => a + b, 0) / lastThird.length

  const difference = lastAvg - firstAvg

  if (Math.abs(difference) < 100) return "Tendencia estable"
  if (difference > 0) return `Tendencia creciente (+${difference.toFixed(0)} puntos)`
  return `Tendencia decreciente (${difference.toFixed(0)} puntos)`
}
